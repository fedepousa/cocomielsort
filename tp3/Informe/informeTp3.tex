\documentclass[a4paper,10pt]{article}
\usepackage{graphicx}
\usepackage{verbatim}
% \usepackage{lstlisting}
\usepackage{subfig}
\usepackage{float}
 \usepackage[spanish]{babel}   %ver bien como es
\usepackage[utf8]{inputenc}


\begin{document}

\tableofcontents

\newpage


\begin{center}
\section*{Aclaraciones Generales}
\addcontentsline{toc}{section}{Aclaraciones Generales} 

\begin{itemize}
\item La implementación de todos los algoritmos se realizó en lenguaje C++.

\item Para calcular los tiempos de ejecución de los algoritmos se utilizó la función gettimeofday(), que se encuentra en la librería $<sys/time.h>$. Dado que dicha función funciona solamente en sistemas operativos de tipo linux, se debe compilar con el flag -DTIEMPOS en este tipo de sistemas para poder hacer uso de las mismas.

\item Para la realización de los gráficos se utilizó Qtiplot
\end{itemize}

\end{center}

\newpage

\section*{Introducci\'on}
\addcontentsline{toc}{section}{Introducci\'on}

En el presente trabajo se busc\'o realizar diferentes aproximaciones a la resoluci\'on del problema MAX-SAT. El problema MAX-SAT es un problema de optimizaci\'on proveniente del problema de decisi\'on SAT. 

El problema SAT se basa es decidir si un conjunto de clausulas en forma normal conjuntiva, tiene alguna asignaci\'on de las variables que las componenen, tal que la evaluaci\'on de todas las clasulas sea verdadera con dicha asignaci\'on.

El problema SAT es un problema muy importante dentro del campo de la teoria de la complejidad, esto se debe a que SAT fue el primer problema que se identific\'o como NP-Completo. El Teorema de Cook demuestra que el algoritmo SAT pertenece a esta clase de algoritmos.

La importancia de este algoritmo no radica solamente en haber sido el primero en ser caracterizado como NP-Completo, se demostr\'o que el problema SAT puede ser reducido al problema 3-SAT, que es basicamente el mismo problema pero en el cual todas las clausulas tienen un m\'aximo de 3 literales. Adem\'as de probar la reducci\'on, se demostro que este problema tambi\'en pertenece a la clase NP-Completo (A diferencia del problema 2-SAT, para el cual se conoce un algoritmo polinomial para resolverlo). Esta reducci\'on del problema a 3-SAT es un resultado importante ya que luego para probar que otros problemas se encuentran tambien en esta clase se utilizaron reducciones a 3-SAT mostrando la equivalencia en cuanto a la complejidad de resoluci\'on.

\section*{Situaciones de la vida real que se pueden modelar utilizando MAX-SAT}
\addcontentsline{toc}{section}{Situaciones de la vida real que se pueden modelar utilizando MAX-SAT} 




\section*{Algoritmo exacto para MAX-SAT}
\addcontentsline{toc}{section}{Algoritmo exacto para MAX-SAT} 
Como su nombre lo indica, el algoritmo exacto para Max-Sat se encarga de resolver el problema exactamente, arrojando la asignacion que valida la mayor cantidad de clausulas posibles. Dado que no se conoce ning\'un algoritmo polinomial para resolver este problema, se implementaron 2 algoritmos de complejidad exponencial. Por un lado se implement\'o un algoritmo de fuerza bruta de simple implementaci\'on pero de muy baja eficiencia, en cuanto a tiempo de ejecuci\'on. Por otro lado se implemento un algoritmo exacto mediante backtracking para poder evitar visitar todas las asignaciones de las variables posibles.

\subsection*{Algoritmo de fuerza bruta}
\addcontentsline{toc}{subsection}{Algoritmo de fuerza bruta}
En este algoritmo la idea es muy simple, se generan absolutamente todas las asignaciones posibles que existen, siendo estas $2^{v}$ donde v es la cantidad de variables. Luego, por cada una de las asignaciones se verifica cuantas clausulas valida, en el momento que una asignaci\'on supera el m\'aximo de clausulas hasta el momento, se actualiza la cantidad de clausulas validadas, as\'i como cual es la asignaci\'on que gener\'o este m\'aximo.

La idea de este algoritmo es tener una resoluci\'on muy simple del problema, es claro que el tiempo de ejecuci\'on va a ser muy malo ya que se revisan todas y cada una de las asignaciones posibles, y estas crecen en orden exponencial en funci\'on de la cantidad de variables. Sin embargo, cabe destacar que el algoritmo provee una resoluci\'on exacta del problema y con baja probabilidad de errores dada la simpleza del mismo.

A continuaci\'on se presenta el pseudoc\'odigo del mismo:

\begin{verbatim}
maxSatExacto(Vector clausulas, int variables)
vector asignacion
int max := 0
inicializar asignacion todos en falso
Para i = 1 hasta 2^variables
    int sat := 0
    Para j = 1 hasta tamanio(clausulas)
       Si haceTrue(asignacion, clausulas[j])
          sat:= sat + 1
       fin si
    fin para
    si sat > max
        actualizar max
        actualizar asignacionMax
    fin si
    asignacion := siguiente(asignacion,i+1)
fin para
devolver asignacionMax, max
\end{verbatim}

Lo que muestra el pseudoc\'odigo anterior es como, por cada asignaci\'on posible, se mira cada clausula y si la funci\'on \emph{haceTrue} devuelve true, entonces se suma 1 a la cantidad de satisfechas por esa asignaci\'on. Por \'ultimo, se mira cual asignaci\'on es la que tiene m\'as clausulas satisfechas.

La funci\'on \emph{haceTrue} lo que hace es simplemente mirar toda la clausula pasada como par\'ametro y ver si algun literal esta asignado como verdadera, cuando encuentra uno deja de buscar y devuelve True. En caso contrario, si llega hasta el final de la clausula, devuelve False. 

Por otro lado, la funci\'on \emph{siguiente} se encarga de modificar para la asignaci\'on para probar con todas las posibles.

\subsection*{Algoritmo de backtracking}
\addcontentsline{toc}{subsection}{Algoritmo de backtracking}

Luego de implementar un algoritmo exacto por fuerza bruta, se busc\'o implementar un algoritmo tambi\'en exacto pero tratando de lograr un menor tiempo de ejecuci\'on. El algoritmo implementado es un algoritmo exacto basado en la t\'ecnica de backtracking para lograr mejores resultados (en cuanto a tiempo de ejecuci\'on), si bien en la siguiente secci\'on se ver\'a que la complejidad temporal es la misma para ambos algoritmos exactos, la t\'ecnica de backtracking provee de herramientas para no tener que consultar necesariamente por cada una de las asignaciones posibles, es en estas podas que este algoritmo mejora los tiempos de ejecuci\'on del anterior.

\bigskip

La idea de este algoritmo es la siguiente: se genera un arbol de asignaciones, donde cada nivel del arbol i, representa todas las asignaciones posibles desde la variable 1 hasta la variable i. Este arbol, es un arbol binario dado que se arranca de la asignacion nula y de all\'i se abren dos caminos, asignarle False a la variable 1, o asignarle True. Luego, cada rama se va bifurcando sucesivamente por cada variable nueva. Como se puede ver, en el peor caso que tengamos que recorrer todo el arbol la cantidad de asignaciones nuevamente esta dada por $2^{v}$ al igual que en el algoritmo exacto.

Una vez que se tiene el arbol de backtracking lo que se hace es comenzar a recorrer el arbol en alguna direcci\'on determinada. Cabe destacar que en el algoritmo implementado siempre se recorre primero la rama correspondiente a asignar falso a la variable y luego la otra.

La mejora del algoritmo radica en no recorrer todas las ramas posibles, esto se realiza de la siguiente manera: Al haber recorrido la primer rama del arbol llegando hasta una hoja, ya se tiene una mejor soluci\'on posible. Luego, cuando se este explorando una rama lo que se hace es fijarse si esa rama ya posee m\'as clausulas insatisfechas que la mejor soluci\'on hasta el momento. En caso afirmativo, la rama ya no sirve ya que no se podra mejorar la soluci\'on y entonces se puede descartar todo el subarbol que pende de esa rama. Entonces se realiza el backtracking para ir por otro camino posible. 

Las principales diferencias con el algoritmo de fuerza bruta son:
\begin{itemize}
\item La implementaci\'on es bastante m\'as complicada ya que como se realiza backtracking, se debe guardar los estados intermedios de toda la rama que se esta analizando para poder volver hacia atras y tomar un nuevo camino. En el algoritmo exacto, cada asignacion se contrasta con las clausulas originales por lo que solo se deben guardar una vez todas las clausulas.
\item El tiempo de ejecuci\'on deberia ser en la mayor\'ia de los casos. Si bien el peor caso no cambiar\'ia es importante destacar que las podas realizadas pueden traer grandes beneficios en cuanto al tiempo de ejecuci\'on. Si, por ejemplo, ya se tuviese una soluci\'on donde n clausulas son insatisfechas y al asignar True a la variable 1, n+1 clausulas se vuelven insatisfacibles entonces se podr\'ia podar toda una mitad del arbol.
\item El algoritmo de fuerza bruta no puede ser influenciado por alguna heur\'istica, mientras que el algoritmo con backtraking si. Lo que se quiere notar con esto, es que por m\'as que ya se tenga una solucion con n clausulas insatisfechas, el algoritmo por fuerza bruta tiene que probar todas las asignaciones posibles; mientras que el algoritmo de backtracking ya puede comenzar podando ramas que tengan m\'as de n clausulas insatisfechas.
\end{itemize}

A continuaci\'on se presenta el pseudoc\'odigo del algoritmo exacto con backtracking:

\begin{verbatim}
pseudo de backtracking
\end{verbatim}

\subsection*{Complejidad de algoritmos exactos}
\addcontentsline{toc}{subsection}{Complejidad de algoritmos exactos}

En primer lugar, se analizar\'a la complejidad del algoritmo realizado por fuerza bruta.

El mismo presenta un ciclo que se realiza $2^{v}$ veces, dado que esa es la cantidad total de asignaciones diferentes, siendo v la cantidad de variables. Una vez dentro de este ciclo, encontramos otro ciclo que itera sobre la totalidad de las clausulas, haciendo que este ciclo se realice c veces. 

Luego, dentro de este ciclo se llama a la funcion haceTrue. Esta funci\'on lo que hace es fijarse en todos los literales de la clausula si se encuentra asignado como verdadero. Dado que el hecho de fijarse es O(1), ya que es mirar un array, y dado que la clausula como mucho tiene 2*v literales (todas las variables negadas y sin negar), se puede ver que esta funci\'on es O(v).

Por \'ultimo, las otras operaciones que se realizan dentro del ciclo principal tienen menor complejidad que lo mostrado anteriormente ya que son asignaciones que toman O(1) o es la funcion siguiente que toma O(v).

Por lo mostrado anteriormente resulta que la complejidad temporal del algoritmo es O($(2^{v})$*c*v)
Como se puede ver, lo importante m\'as alla de la complejidad exacta, es que este algoritmo es exponencial en funci\'on de la cantidad de variables. Cabe destacar que si bien se podri\'an encontrar algoritmos con mejor complejidad, esta no podr\'ia ser menor que exponencial en el caso que se quieran revisar todas las asignaciones posibles.

\bigskip

Complejidad del algoritmo exacto con backtracking:

Para realizar el c\'alculo de complejidad de este algoritmo tomaremos el peor caso posible. El mismo consiste en que ninguna rama sea podada y por lo tanto se tengan que revisar todos los nodos posibles del arbol. En este caso el ciclo principal que itera sobre todas las asignaciones posibles ser\'ia O($2^{v}$), ya que este es el orden de la cantidad de nodos del arbol. 

Luego, hay que analizar cuales son las operaciones que se realizan cada vez que el algoritmo se encuentra en un nuevo nodo. En primer lugar, se llama a la funci\'on resolver, la misma tiene un funcionamiento an\'alogo al explicado en el algoritmo por fuerza bruta; se fija en cada clausula si la misma se hizo verdadera, y cuenta las insatisfacibles, por lo que esta funcion toma O(c*v) operaciones. Luego, lo que se hace es copiar todo el estado al siguiente nodo para que se pueda procesar, al realizar esto se copian varios par\'ametros. Sin embargo, el orden temporal de esta copia esta dado por el orden que toma copiar todas las clasulas, dado que los dem\'as par\'ametros que se copian tienen menor orden espacial ya que son solamente vectores. 

Se puede ver que copiar todo el estado toma O(c*v) operaciones ya que lo que se hace es copiar absolutamente todas las clausulas, donde cada una pueda tener hasta 2*v literales por lo justificado anteriormente.

Por \'ultimo, resumiendo lo anteriormente explicado se puede ver que cuando se revisa un nodo se toma O(c*v) operaciones, y en el peor caso hay que revisar O($2^{v}$) nodos; por lo que la complejidad total de este algoritmo es O($(2^{v})$*c*v).

Como se puede ver, la complejidad del algoritmo de backtracking no es mejor que el algoritmo exacto por fuerza bruta, sigue siendo exponencial. De hecho, se puede notar que en el peor caso posible, el algoritmo de backtracking es m\'as lento que el algoritmo por fuerza bruta dado el overhead que produce copiar todo el estado al siguiente nodo del arbol para que se pueda procesar.

Sin embargo, en la mayor\'ia de los casos, el algoritmo con backtracking presenta resultados temporalmente mejores que el algoritmo de fuerza bruta ya que se podan varias ramas haciendo que no se tenga que visitar todas las asignaciones posibles.

\medskip

Cabe destacar que la ventaja temporal que gana el algoritmo de backtracking, genera una mayor complejidad espacial ya que en todo momento se debe tener todos los estados de los nodos de la rama que se esta visitando para poder caminar hacia atras. Luego la complejidad espacial del algoritmo de fuerza bruta es O(c*v) ya que se guardan una vez todas las clausulas, mientras que la complejidad espacial del algoritmo de backtracking es O(c*v*v) ya que se guardan todas las clausulas una vez por cada nodo de la rama que se esta analizando, que a lo sumo tiene v nodos.




\section*{Heur\'istica constructiva para MAX-SAT}
\addcontentsline{toc}{section}{Heur\'istica constructiva para MAX-SAT} 
En esta secci\'on se explicar\'a el uso de una heur\'istica constructiva para resolver el problema.

La motivaci\'on principal de utilizar diferentes heur\'isticas para resolver el problema de Max-Sat es que, como se vio en la secci\'on anterior, los algoritmos exactos conocidos son de orden exponencial por lo que solo se pueden correr con instancias relativamente peque\~{n}as.

La idea entonces es realizar un algoritmo que no sea exacto, sino que arroje una soluci\'on aproximada, pero en un tiempo polinomial para poder correr instancias m\'as grandes.

En esta primer aproximaci\'on, se realiz\'o una heur\'istica constructiva, esto quiere decir que se va construyendo una soluci\'on mediante alg\'un criterio que se supone (y luego se ver\'a que se puede demostrar) que es adecuado para obtener un buen resultado.

En este caso, la heur\'istica constructiva seguir\'a una estrategia golosa para ir armando la soluci\'on. Lo que hace esta heur\'istica es revisar todas las clausulas buscando cual es el literal que m\'as se repite. Una vez encontrado dicho literal lo que se hace es asignar True a este literal y actualizar las clausulas en base a esta asignaci\'on.

Actualizar las clausulas consiste en dos tareas, en primer lugar se borran todas las clausulas que contenian este literal ya que ya fueron satisfechas mediante la asignaci\'on y se actualiza el contador de clausulas satisfechas. Por otro lado, en las clausulas restantes, se borra el literal negado ya que este no sirve para futuras elecciones porque al asignar True al literal elegido, el literal negado tendra necesariamente valor falso.

Luego de realizar esta actualizaci\'on, se continua iterativamente con esta estrategia golosa hasta encontrar una asignaci\'on completa de las variables.

A continuaci\'on se muestra el pseudoc\'odigo de la heur\'istica constructiva:

\begin{verbatim}
Constructiva(Vector clausulas, int V)
Max := 0
Comenzar con asignacion vacia
mientras asignacion no este completa
      Tomar literal l que mas se repita
      Asignar True a l
      Para i de 1 hasta tamanio(clausulas)
         Si esta(l, clausula[i])
             borrar clausula[i]
             Max := Max + 1
         fin si
      fin para
      Para i de 1 hasta tamanio(clausulas)
         Si esta(-l, clausula[i])
             borrar(-l, clausula[i])
         fin si
      fin para
fin mientras
devolver asignacion y Max
\end{verbatim}

\subsection*{Aproximaci\'on del resultado}
\addcontentsline{toc}{subsection}{Aproximaci\'on del resultado}

Es importante destacar que a priori esta heur\'istica podr\'ia arrojar resultados que no se acercasen al verdadero valor del problema. La heur\'istica parece razonable ya que siempre se elige el literal que m\'as clausulas satisface, y luego se va iterando hasta que no queden m\'as variables para asignar. Es importante destacar que si bien la heur\'istica parece razonable se puede encontrar rapidamente casos en los cuales esta aproximaci\'on golosa no nos devuelva el resultado exacto. Dada estas observaciones, se busc\'o encontrar algun tipo de cota para el resultado entregado por la heur\'istica, en funci\'on del verdadero resultado.

Dada esta heur\'istica golosa, se puede ver que en realidad se trata de un algoritmo aproximado. Si se denota $c_{max}$ como la cantidad m\'axima de clausulas satisfacibles, $c_h$ al resultado entregado por la heur\'istica y m al m\'inimo n\'umero de literales contenido en cualquiera de las clausulas, se cumple que\footnote{Cita Bibliogr\'afica 1}:


\begin{equation}
c_h \geq \frac{m}{m+1}*c_{max}
\end{equation}

Dada la ecuaci\'on anterior, se tiene una cota para el resultado que depende del m\'inimo n\'umero de literales en cualquier clausula. Cabe destacar que en la implementaci\'on de esta heur\'istica, y en los casos de prueba utilizados, no se hace ninguna menci\'on particular a la cantidad m\'inima de literales de las clausulas. En este caso, podemos acotar por el peor caso que ser\'ia tener clausulas de un solo literal.

En dicho caso, la heur\'istica utilizada ser\'ia un algoritmo $\frac{1}{2}$-aproximado, es decir que el resultado arrojado jam\'as se encontrara por debajo de la mitad del valor real del problema. En el caso del que el m\'inimo n\'umero de clausulas suba (lo que suele pasar en la pr\'actica), la cota tambi\'en se ajustar\'a dando una mejor aproximaci\'on.

\subsection*{Complejidad de la heur\'istica constructiva}
\addcontentsline{toc}{subsection}{Complejidad de la heur\'istica constructiva}

La heurística elige de manera golosa el literal que más clausulas satisface y lo hace verdadero. Esto se repite hasta que la asignación de las variables esté completa.

Para elegir el literal que más clausulas satisface manetenemos, por cada literal, un conjunto con las clausulas que haría verdaderas y que todavía no están satisfechas.

Al realizar cada elección debemos actualizar la estructura, eliminando cada una de las cláusulas satisfechas de los conjuntos en los que aparezcan. Como tenemos un conjunto por cada literal, se van a borrar las cláusulas satisfechas de $v$ conjuntos, donde $v$ es la cantidad de variables del problema. En el algoritmo se van a satisfacer a lo sumo $c$ cláusulas. Por lo tanto a cada cláusula satisfecha vamos a borrarla de $v$ conjuntos, teniendo el borrado una complejidad en $O\left( log \left( c \right) \right)$, donde $c$ es la cantidad de cláusulas del problema. Por lo tanto, mantener la estructura va a tener una complejidad en $O\left( c \times v \ times log \left( c \right) \right)$.

El conjunto utilizado para guardar las clausulas que haría verdaderas un literal está implementado en una estructura de árbol que nos garantiza inserción y borrado en $O\left( log \left( e \right) \right)$, donde $e$ es la cantidad de elementos del conjunto.

Como tenemos que recorrer todas las variables en cada asignación para mantener la estructura, podemos llevar un registro de cuál es el literal que más cláusulas, entre las aún insatisfechas, haría verdaderas. 

Por lo tanto la complejidad del algoritmo es $O\left( c \times v \ times log \left( c \right) \right)$.



\section*{Heur\'istica de b\'usqueda local para MAX-SAT}
\addcontentsline{toc}{section}{Heur\'istica de b\'usqueda local para MAX-SAT} 

La segunda he\'uristica implementada fue la de busqueda local. Como su nombre lo indica, lo que hace esta heur\'istica es pararse sobre una soluci\'on y buscar localmente si se puede mover a otra soluci\'on \emph{cercana} con m\'as clausulas satisfechas. Dada la explicaci\'on anterior, se desprende que entonces se debe definir que significa que dos soluciones cercanas. Teniendo una asignaci\'on posible, se define una vecindad de asignaciones mediante alg\'un criterio que ser\'an las asignaciones \emph{cercanas} mencionadas anteriormente.

La idea principal de la heur\'istica es empezar con alguna asignaci\'on posible y luego buscar en la vecindad de esta soluci\'on si existe alguna asignacion que satisfaga mayor cantidad de variables, si existe esta nueva asignaci\'on, entonces se cambia la asignaci\'on m\'axima actual por esta nueva y se vuelve a realizar una busqueda local, ahora con la vecindad de la nueva asignaci\'on.

Esta heur\'istica finaliza cuando tenemos una asignaci\'on que es la mejor de todas entre ella y las asignaciones de su vecindad. Es decir, cuando se encuentra un m\'inimo local, la heur\'istica para y devuelve la mejor asignaci\'on encontrada hasta el momento.

Es importante destacar que la heur\'istica de busqueda local necesita de una asignaci\'on inicial para comenzar a definir su vecindad y luego realizar la busqueda. Como una primera aproximaci\'on se podr\'ia inicializar la heur\'istica con cualquier asignaci\'on, por ejemplo todas las variables en falso, el problema es que para caso de prueba diferente el espacio de asignaciones tiene una forma diferente. Esto puede llevar a que si inicializamos en cualquier asignaci\'on, se encuentre rapidamente un m\'aximo local que poco tenga que ver con la soluci\'on real del problema. 

La soluci\'on que se utiliz\'o para el problema explicado anteriormente es que la heur\'istica de busqueda local sea inicializada con el resultado proviniente de aplicar la heur\'istica constructiva.

Es importante notar que la heur\'istica de busqueda local no tiene permitido moverse a una asignaci\'on que satisfaga una menor cantidad de clausulas, por lo que se puede ver que el resultado arrojado por la busqueda local es mejor o igual que el resultado de la heur\'istica constructiva en el caso de que se inicialice el procedimiento con el resultado de la heur\'istica constructiva.

De esta manera, reemplazando en la ecuaci\'on (1) (denotado $c_{local}$ al resultado de la busqueda local):

\begin{equation}
c_{local} \geq c_{constr} \geq \frac{m}{m+1}*c_{max}
\end{equation}

Luego, dada la ecuaci\'on anterior y con una explicaci\'on an\'aloga a la propuesta en la heur\'istica constructiva, se puede ver que esta heur\'istica (inicializada de esta manera) tambi\'en se trata de un algoritmo $\frac{1}{2}$-aproximado y, de la misma manera, a medida que el m va subiendo, la cota va mejorando.


\subsection*{Detalles de implementaci\'on}
\addcontentsline{toc}{subsection}{Detalles de implementaci\'on}

En primer lugar, es importante destacar como se definio la vecindad de una asignaci\'on, para tener bien definido a donde se va a realizar la busqueda local dada una asignaci\'on. Se determin\'o que la vecindad de una asignaci\'on esta dada por todas las asignaciones que solo distan en una variable. Es decir, las asignaciones que tienen todas las variables asignadas igual excepto por una.

Luego, se decidio crear una estructura que dada cada variable, se tiene listado en que clausulas aparece y si el literal que aparece es la variable o su negaci\'on. Sumado a esto, se tiene listado por cada clausula que literales tienen. Por otro lado, se tiene un vector de valores de verdad que indican los estados de las variables y un vector de enteros que indica por cada clausula cuantos literales hacen verdadera la clausula.

Dada esta estructura, se procede hacer la busqueda local hasta caer en una soluci\'on inmejorable, respecto de la vecindad definida anteriormente. Es decir, se toma la asignaci\'on actual y se va modificando de a una variable y se actualizan las estructuras adecuadamente para ver si esta nueva configuraci\'on es mejor que la actual. 

El pseudoc\'odigo de la heur\'istica de busqueda local es:

\begin{verbatim}
BusquedaLocal(Vector clausulas, int V)
Max := HeuristicaConstructiva(clausulas, v)
asignacionMax := HeuristicaConstructiva(clausulas, v)
mientras cambie la asignacion
      asignacionMaxTemp := asignacionMax
      para toda asignacion_i en la vecidad de asignacionMax
         si asignacion_i satisface mas que asignacionMax
            asignacionMaxTemp := asignacion_i
         fin si
      fin para
      asignacionMax := asignacionMaxTemp
fin mientras
devolver asignacion y Max
\end{verbatim}

\subsection*{Complejidad de la heur\'istica de busqueda local}
\addcontentsline{toc}{subsection}{Complejidad de la heur\'istica de busqueda local}

El algoritmo consiste en elegir la variable que al cambiar su asignación más aumenta el número de clausulas satisfechas. En caso de no existir ninguna variable que al cambiar su asignación aumente el número de cláusulas satisfechas, se termina, si no se vuelve a iterar.

Para identificar la variable a la que se le cambiará su asignación mantenemos por cada cláusula el número de literales que aparecen en la misma y que son verdaderos con la asignación actual. Llamemos $l_i$ al número de literales que aparecen en la cláusula $i$ y que son verdaderos con la asignación actual. A su vez mantenemos para cada variable, una lista de las cláusulas en las que aparece un literal que la contenga y si el literal que la contiene es una negación. 

Para saber cuál sería la variación de la cantidad de cláusulas satisfechas al cambiar el valor de una varible, necesitamos saber cuántas cláusulas pasaron a ser verdaderas y cuántas ahora son falsas. Para eso, en cada cláusula en que aparece la variable restamos uno a $l_i$ si la variable satisfacía un literal de la cláusula $i$, o sumamos uno si ahora satisface un literal de la misma cláusula que era falso. Si $l_i$ es cero antes del cambio y luego es distinto de cero, entonces antes era falsa la cláusula y el cambio la hizo verdadera, por el contrario, si $l_i$ es distinto de cero antes del cambio y luego se hace cero, la cláusula $i$ dejo de ser satisfecha luego del cambio. Llevando un registro de cuántas cláusulas cambiaron de estar satisfechas a insatisfechos y viceversa. 


Por lo tanto, para obtener la variación del número de cláusulas satisfechas al cambiar una variable se realiza una cantidad de operaciones en $O\left( c \right)$, donde $c$ es la cantidad de variables del problema. Como es necesario hacer esto para cada una de las variables, cada iteración tiene una complejidad en $O\left( v \times c  \right)$.

La inicialización de la estructura se realiza en $O\left( v \times  c\right)$ ya que es necesario recorrer todas las clausulas, y en cada cláusulas la cantidad de literales está en $O\left( v\right)$. La inicialización consiste en, a medida que se recorren las cláusulas, por cada literal que aparece, agregar la cláusula que se está recorriendo a la lista de clausulas en las que la variable contenida en el literal aparece. Si el literal es satisfechos por la asignación inicial, sumar uno a $l_i$, siendo i la cláusula que se está recorriendo. 


La cantidad de iteraciones está acotada por la cantidad de cláusulas, ya que en cada iteración aumenta el número de cláusulas satisfechas. Por lo tanto el algoritmo tiene una complejidad en $O\left( v \times c^2 \right)$.


\section*{Metaheur\'istica de b\'usqueda tab\'u para MAX-SAT}
\addcontentsline{toc}{section}{Metaheur\'istica de b\'usqueda tab\'u para MAX-SAT} 

La meteheur\'istica de busqueda tabu surge para mejorar la heur\'istica de busqueda local, ya que esta puede caer en m\'aximos locales que esten muy lejos del m\'aximo absoluto del problema.

Es por esto que la busqueda tab\'u resulta de modificar la b\'usqueda local con la motivaci\'on de poder salir de asignaciones que resultan \'optimas localmente; es decir, asignaciones que satisfacen una cantidad de clausulas mayor o igual a las que satisface cualquier otra asignaci\'on en su vecindad.

La metaheur\'istica de b\'usqueda tab\'u consiste basicamente en modificar el vecindario de cada asignaci\'on. Esto se realiza excluyendo asignaciones que fueron visitadas recientemente y relajando el criterio de parada de la b\'usqueda local, permitiendo que se continue la b\'usqueda a\'un cuando la mejor asignaci\'on del vecindario no aumente la cantidad de clausulas satisfechas. 

Es importante destacar que la exclusi\'on de las asignaciones visitadas m\'as recientemente no es un detalle menor. Si no se hiciese esto se entrar\'ia en un cilco entre el \'optimo local y la mejor asignaci\'on de su vecindad, sin poder alejarnos de estas asignaciones, para buscar mejores soluciones.

Luego de lo explicado anteriormente, se denota que para poder separar las asignaciones visitadas recientemente se debe implementar alg\'un tipo de memoria. Una aproximaci\'on inicial ser\'ia guardar una lista de longitud acotada con las \'ultimas asignaciones visitadas y excluir dichas asignaciones del vecindario que se considere. Se denominar\'a lista Tab\'u a dicha lista.

En esta primera implementaci\'on presentada, ya se pueden encontrar varias sutilezas que resultan factores importantes para el desarrollo de la metaheur\'istica. Por ejemplo, la longitud de la lista Tab\'u es acotada y la cota para la misma puede ser fija, pero tambi\'en podr\'ia estar expresada en funci\'on de alg\'un par\'ametro o incluso podr\'ia variar durante la ejecuci\'on. Algo similar ocurre con el criterio de parada; es com\'un que est\'e expresado como una combinaci\'on de restricciones en la cantidad m\'axima de iteraciones y la cantidad de iteraciones desde la \'ultima asignaci\'on que mejor\'o la cantidad conocida de clausulas satisfechas.

Si bien la primera aproximaci\'on indica que la lista Tab\'u ser\'ia una lista de asignaciones, es importante destacar que esta implementaci\'on resulta ineficiente, debido a que se debe recorrer toda la lista para saber si una asignaci\'on est\'a o no. Esto resulta ineficiente adem\'as porque la comparacion entre asignaciones es lenta, ya que es necesario compara variable por variable para ver si se realmente coinciden.

Una alternativa que se encarga de resolver este \'ultimo problema consiste en representar la vecindad de una asignaci\'on en t\'ermino de movimientos que se puede realizar desde la asignaci\'on original a alguna otra de la vecindad. Si los movimientos que se consideran son reversibles, entonces se puede guardar en la lista Tab\'u los movimientos opuestos a los que se realizaron, evitando de esta manera entrar en el ciclo anteriormente mencionado. Se denominar\'a movimientos Tab\'u a aquellos que se encuentra en esta nueva lista Tab\'u.

A partir de la modificaci\'on explicada anteriormente puede surgir un inconveniente. Podr\'ia ocurrir que un movimiento a una asignaci\'on que todav\'a no se visit\'o sea Tab\'u, y esta asignaci\'on podr\'ia incluso satisfacer m\'as clausulas que cualquier otra visitada con anterioridad. En casos como \'este ser\'ia deseable ignorar la condici\'on de Tab\'u del movimiento. 

Es por lo explicado anteriormente que surge la funci\'on de asipraci\'on. En este problema se decidi\'o ignorar la condici\'on de Tab\'u de un determinado movimiento aplicado a una asignaci\'on si la asignaci\'on resultante satisface m\'as clausulas que la mejor asignaci\'on visitada hasta el momento.


Implementaci\'on:
Habiendo definido conceptualmente los componentes de la b\'usqueda Tab\'u, se pueden mencionar algunos detalles de la implementaci\'on.

En primer lugar, al igual que en la b\'usqueda local, la vecindad que se definio para cada asignaci\'on est\'a compuesta por las asignaciones resultantes de cambiar el valor de exactamente una variable de la asignaci\'on original. Cada movimiento es el cambio de una variable, por lo tanto manteniendo un vector de enteros del tama\~{n}o de la cantidad de variables, se puede llevar un registro de cu\'al fue la \'ultima iteraci\'on en la se aplic\'o el movimiento i. De esta manera, se puede saber si un movimiento es Tab\'u con s\'olo ver si pasaron suficientes iteraciones desde la \'ultima iteraci\'on en la que fue usado, lo que resulta m\'as eficiente que recorrer una lista con los movimientos.


(aca habria que ver de decir si es algo-aproximado)

\subsection*{Complejidad de la metaheur\'istica de la b\'usqueda Tab\'u}
\addcontentsline{toc}{subsection}{Complejidad de la metaheur\'istica de la b\'usqueda Tab\'u}


ESCRIBIR ESTO BIEN!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Mismo que local, excepto que la cantidad de iteraciones máxima la pone uno, si no, es la cantidad de cláusulas por la cantidad de iteraciones entre maximos por c  por v, que es la complejidad de la iteracion.


\subsection*{Modificaci\'on de la metaheur\'istica de la b\'usqueda Tab\'u}
\addcontentsline{toc}{subsection}{Modificaci\'on de la metaheur\'istica de la b\'usqueda Tab\'u}

Para finalizar con las heur\'isticas para resolver el problema de Max-Sat, se implemento una modificaci\'on a la meteheur\'istica de b\'usqueda Tab\'u.

ESCRIBIR ESTO BIEN!!!!!!!!!!!!!!!!
Se generan asignaciones iniciales al azar, con probabilidad un medio para true en cada variable. Se ejecuta tabu con cada asignacion. Se devuelve el mejor resultado.

\section*{Filtro de componentes conexas}
\addcontentsline{toc}{section}{Filtro de componentes conexas}


\section*{An\'alisis de resultados}
\addcontentsline{toc}{section}{An\'alisis de resultados}


Para analizar todos los algoritmos exactos y las heur\'isticas propuestas, se realizaron varios casos de prueba. Este an\'alisis se encuentra divido en 3 partes diferentes, cada una con un objetivo diferente, las mismas son:

\begin{itemize}
\item An\'alisis de todos los algoritmos exactos y heur\'isticas.
\item An\'alisis comparativos de las heur\'isticas constructiva, de b\'usqueda local y de b\'usqueda tab\'u.
\item An\'alisis comparativos de variaciones de par\'ametros en tab\'u y tab\'u modificada.
\end{itemize}
 

En todos los casos, los an\'alisis se centraran en dos aspectos: Calidad de la soluci\'on encontrada y tiempo de ejecuci\'on requerido.

Para los diferentes an\'alisis de resultados se utilizar\'on paquetes de prueba provenientes de \emph{The Satiasfibility Library}\footnote{http://people.cs.ubc.ca/~hoos/SATLIB/benchm.html}. Los mismos proveen de varios casos de prueba con diferentes n\'umeros de clausulas y variables. Cabe destacar que en todos los paquetes utilizados todas las clausulas son satisfacibles por lo que el resultado exacto de Max-Sat es exactamente el n\'umero de clausulas presentes en el paquete.

Por otro lado, dado que estos paquetes presentan un formato diferente al formato requerido, se encuentra el archivo \emph{benchmarks.cpp}. El mismo realiza la conversi\'on del formato de los paquetes al formato requerido y corre todos los casos de prueba a la vez\footnote{Para instrucciones sobre como utilizar el mismo ver ap\'endice 2}

\subsection*{An\'alisis de todos los algoritmos exactos y heur\'isticas}
\addcontentsline{toc}{subsection}{An\'alisis de todos los algoritmos exactos y heur\'isticas}

En esta secci\'on se presentar\'a los resultados obtenidos al correr todos los algoritmos y heur\'isticas con los mismos casos de prueba. 

Esta secci\'on no presenta demasiados resultados por dos motivos:

En primer lugar existe el problema de que para correr los casos de prueba con el algoritmo de fuerza bruta, se toma un tiempo considerable dado su naturaleza. Por otro lado, los casos presentados ser\'an suficientes para mostrar las tendencias de los algoritmos exactos, mientras que un an\'alisis m\'as hexaustivo de las heur\'isticas se presentar\'a en las secciones siguientes.

\medskip

Para esta secci\'on se utilizaron 5 casos de prueba de 20 variables y 91 clausulas, todas satisfacibles. Dado que los diferentes algoritmos son varios, los resultados se presentan a modo de tabla.


Aca ponemos la tabla


Dada la tabla presentada anteriormente, se denotan varias observaciones:

\begin{enumerate}
\item Los resultados muestran como los algoritmos exactos devuelven 91 en todos los casos, funcionando correctamente; Mientras que las heur\'isticas no devuelven siempre los resultados exactos, como era de esperar.
\item Los tiempos de ejecuci\'on de los algoritmos exactos respecto de las heur\'isticas son considerablemente mayores: En el caso del algoritmo de fuerza bruta, se puede ver como el tiempo de ejecuci\'on es varios ordenes de magnitud m\'as grande que los tiempos requeridos por las heur\'isticas.

En el caso del algoritmo con backtracking, se puede ver que el tiempo de ejecuci\'on es considerablemente peor que el tiempo de las heur\'isticas. Sin embargo, es bastante mejor que el tiempo del algoritmo de fuerza bruta.

Cabe destacar que, en estos casos, el tiempo de backtracking no es tan malo en comparaci\'on con las heur\'isticas. Se cree que esto se debe principalmente a que las 91 clausulas son satisfacibles y el algoritmo de backtracking tiene peor rendimiento cuando la mayor\'ia de las clausulas no se satisfacen, ya que se le hace m\'as complicado podar ramas.
\item Los casos presentados muestran como el filtro de componentes conexas no presenta una mejora en los tiempos de ejecuci\'on, si no que empeoran debido al tiempo que se pierde en las rutinas pertinentes a este filtro. Se cree que la razon para que suceda esto es que a medida que la cantidad de variables crece, cada vez es menos probable que las clausulas no se relacionen entre s\'i, formando una sola componente conexa. Es por esto que para las secciones siguientes no se segu\'iran analizando las variantes con el filtro de componentes conexas.
\item Los casos presentandos alcanzan para ver las diferencias, de eficiencia y temporales, que hay entre los algoritmos exactos y las heur\'isticas pero no son representativos para comparar las heur\'isticas entre s\'i. Esto se har\'a en las secciones siguientes.
\end{enumerate}


\subsection*{An\'alisis comparativos de las heur\'isticas constructiva, de b\'usqueda local y tab\'u}
\addcontentsline{toc}{subsection}{An\'alisis comparativos de las heur\'isticas constructiva, de b\'usqueda local y tab\'u}

En esta secci\'on se realizar\'a un an\'alisis comparativo entre las diferentes he\'uristicas. Para hacer este an\'alisis se utilizaron varios paquetes de prueba:

\begin{enumerate}
\item 1000 instancias con 50 variables y 218 clausulas, todas satisfacibles.
\item 100 instancias con 75 variables y 235 clausulas, todas satisfacibles.
\item 1000 instancias con 100 variables y 430 clausulas, todas satisfacibles.
\item 100 instancias con 125 variables y 538 clausulas, todas satisfacibles.
\item 100 instancias con 150 variables y 645 clausulas, todas satisfacibles.
\item 100 instancias con 175 variables y 753 clausulas, todas satisfacibles.
\item 100 instancias con 200 variables y 860 clausulas, todas satisfacibles.
\item 100 instancias con 225 variables y 960 clausulas, todas satisfacibles.
\item 100 instancias con 250 variables y 1065 clausulas, todas satisfacibles.
\end{enumerate}

Dado que la cantidad de pruebas corridas es muy grande como para presentar los resultados individuales de cada caso, se procedio a realizar el an\'alisis de la siguiente manera: para cada una las heur\'isticas diferentes se considerar\'a un \emph{N\'umero de eficiencia}, el mismo se realiza para cada uno de los paquetes por separado y se calcula mediante la cuenta 

\begin{equation}
 Eficiencia = promedio de clausulas satisfechas/clausulas totales
\end{equation}

Es decir, se genera un n\'umero que indica porcentualmente cuantas clausulas en promedio satisfizo una heur\'istica determinada para cada paquete.

En el siguiente gr\'afico se puede ver el desempe\~{n}o de las heur\'isticas. El mismo presenta el n\'umero de eficiencia de la heur\'istica en funci\'on de los paquetes de prueba.


Aca va el grafico 1.


Dado el gr\'afico presentado se pueden hacer varias observaciones:
\begin{itemize}
\item Las heur\'isticas muestran resultados esperados: En primer lugar, con la eficiencia m\'as baja se encuentra la heur\'istica constructiva (Se destaca que igualmente el comportamiento es muy bueno, superando el 97,5 porciento de clausulas satisfechas en promedio). En segundo lugar se encuentra la b\'usqueda local, lo cual es natural dado que la misma empieza desde la soluci\'on provista por la constructiva y luego la mejora. Por \'ultimo, se puede ver que la metaheur\'istica de b\'usqueda tab\'u es la m\'as eficiente de la tres, dando un salto de calidad importante llegando casi al 99,5 porciento de clausulas satisfechas en promedio en todos los paquetes.
\item Las 3 heur\'isticas poseen un comportamiento porcentual parecido en los 9 paquetes, mostrando que la eficiencia parece depender intrinsecamente de las elecciones hechas por las rutinas, y no por otros factores como la cantidad de variables o de clausulas.
\end{itemize}


A continuaci\'on se muestra el an\'alisis de los tiempos de ejecuci\'on de cada una de las heur\'isticas para estos paquetes de casos de prueba.


Aca va el gr\'afico 2.



Como se puede ver en la figura 2, la heur\'istica constructiva es la que menos tiempo de ejecuci\'on toma lo cual concuerda con lo esperado ya que las otras dos heur\'isticas comienzan con la soluci\'on de la constructiva. Luego, se encuentra la heur\'istica de b\'usqueda local y por \'ultimo, con mayor tiempo de ejecuci\'on, se encuentra la b\'usqueda tab\'u.

Cabe destacar que la diferencia en los tiempos de ejecucion entre la heur\'istica constructiva y la b\'usqueda local no es muy grande, mientras que la diferencia con tab\'u si es bastante mayor. Esto indicar\'ia que si bien la busqueda local mejora los resultados de la heur\'istica constructiva(como se ve en el gr\'afico 1), no toma mucho tiempo en hacerlo ya que rapidamente cae en un m\'aximo local. Por otro lado, la b\'usqueda tab\'u si toma un tiempo mayor, porque aunque caiga en m\'aximos locales, sigue buscando dada su naturaleza, es esta brecha en el tiempo de ejecuci\'on la que explica la clara diferencia en la eficiencia de tab\'u al realizar una b\'usqueda m\'as exahustiva.

\bigskip

La eficiencia superior que mostr\'o la b\'usqueda tab\'u, motiva la siguiente secci\'on de an\'alisis realizada para hacer m\'as hincapie en la eficiencia de esta metaheur\'istica, as\'i como la de su modificaci\'on implementada.

\subsection*{An\'alisis comparativos de variaciones de par\'ametros en b\'usqueda tab\'u y tab\'u modificada}
\addcontentsline{toc}{subsection}{An\'alisis comparativos de variaciones de par\'ametros en b\'usqueda tab\'u y tab\'u modificada}

En primer lugar, se destaca que el an\'alisis de todos los casos siguientes se realiz\'o de la misma manera que en la secci\'on anterior; es decir, se utilizaron los mismos nueve paquetes de casos de prueba, y para resumir el desempe\~{n}o se utiliz\'o el mismo n\'umero de eficiencia presentado anteriormente.

Una vez realizadas dichas consideraciones, se proceder\'a a realizar el an\'alisis pertinente. Dicho an\'alisis esta basado en las siguientes propiedades: 

La metaheur\'istica de b\'usqueda tab\'u posee tres par\'ametros que son modificables, los mismos son: Longitud de la lista tab\'u, Cantidad m\'axima de iteraciones y Cantidad m\'axima de iteraciones entre \'optimos. Es por esto que lo se har\'a es analizar como var\'ia la eficiencia y el tiempo de ejecuci\'on de la b\'usqueda tab\'u al modificar estos par\'ametros.

Por otro lado, la b\'usqueda tab\'u modificada presenta un par\'ametro m\'as que es la cantidad de asignaciones con las que se trabaja, por lo que el \'ultimo an\'alisis presentado sera pertinente a la variaci\'on de este par\'ametro.

\bigskip

En primer lugar, se comenzar\'a el an\'alisis fijando los par\'ametros de cantidad de iteraciones, y se modificar\'a la longitud de la lista tab\'u. La longitud de la lista tab\'u se vari\'o entre v/3 y v/9

A continuaci\'on, se puede ver el gr\'afico de la eficiencia en funci\'on de cada paquete. 

Aca va el grafico 3.

Dado el gr\'afico de la figura 3, se puede ver como var\'ia la eficiencia de la b\'usqueda tab\'u dependiendo de la longitud de la lista. La conclusi\'on principal que se desprende de la visualizaci\'on del gr\'afico es que las franjas centrales se encuentran por encima de las franjas laterelas. Es decir, parecer\'ia ser que la metaheur\'istica funciona de mejor manera cuando la longitud de la lista se encuentra entre v/5, v/6 y v/7 y comienza a bajar su eficiencia a medida que la longitud se aleja de estos valores.

En el gr\'afico se denota que en los primeros paquetes v/5 parece ser la longitud m\'as eficiente, mientras que en los \'ultimos paquetes es v/6 la que aparece por encima de las dem\'as. v/7 solo es la m\'as eficiente en el 4to paquete, pero en todos los demas se encuentra cerca del m\'aximo.

Es importante destacar que si bien se encuentran fluctuaciones y tendencias, todas las longitudes propuestas se encuentran en un margen muy chico, resultando todas muy eficientes.

Por \'ultimo, se destaca que las tendencias vistas sobre la mejor longitud para la lista tab\'u se condice con los resultados encontrados en la bibliograf\'ia.\footnote{Citar el paper que habla de v/6}

\bigskip

A continuaci\'on, se presenta el gr\'afico de los tiempos de ejecuci\'on de la metaheur\'istica al cambiar la longitud de la lista tab\'u.

Aca va el grafico 4.



Como se puede ver en el gr\'afico, no hay grandes fluctuaciones entre los tiempos de ejecuci\'on y se encuentra ninguna tendencia muy definida. (poner a que se debe esto, a que mirar si esta es O(1) y no miras toda la lista tonces da igual?)



\section*{Conclusiones}
\addcontentsline{toc}{section}{Conclusiones}

\section*{Ap\'endice 1: Bibliograf\'ia}
\addcontentsline{toc}{section}{Ap\'endice 1: Bibliografia}

\begin{itemize}
\item Algorithms for the Maximum Satiasfiability Problem 
\end{itemize}

\section*{Ap\'endice 2: Instrucciones para utilizar benchmarks.cpp}
\addcontentsline{toc}{section}{Instrucciones para utilizar benchmarks.cpp}

\end{document}
